{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage import exposure\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11930504189853008979]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config = tf.compat.v1.ConfigProto(config=tf.ConfigProto(log_device_placement=True))\n",
    "# sess = tf.compat.v1.Session(config=config) \n",
    "# K.set_session(sess)\n",
    "\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# print(device_lib.list_local_devices())\n",
    "# K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset \n",
    "https://drive.google.com/drive/u/3/folders/1sHh6NvuKX6RB5OytLwf4kaqfQ9svJNDQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# It's a multi-class classification problem \n",
    "class_index = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "               'dog': 5, 'frog': 6,'horse': 7,'ship': 8, 'truck': 9}\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://img-blog.csdnimg.cn/20190623084800880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMDEz,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to one-hot encoding (keras model requires one-hot label as inputs)\n",
    "num_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AHE(img):\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    return img_adapteq\n",
    "\n",
    "# train_datagen = ImageDataGenerator()\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     preprocessing_function=AHE,\n",
    "#     rescale=1,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "    \n",
    "# train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.EarlyStopping at 0x7ffb01b0fe10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Builde model\n",
    "# model = Sequential() # Sequential groups a linear stack of layers \n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=x_train.shape[1:])) # Add Convolution layers\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3))) # Add Convolution layers\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(MaxPooling2D(pool_size=(4, 4))) # Add Max pooling to lower the sptail dimension\n",
    "\n",
    "# model.add(Flatten()) # Flatten the featuremaps\n",
    "# model.add(Dense(units=512)) # Add dense layer with 512 neurons\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(Dense(units=num_classes)) # Add final output layer for 10 classes\n",
    "# model.add(Activation('softmax')) # Add softmax activation to transfer logits into probabilities\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), input_shape=x_train.shape[1:], activation =\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Conv2D(64, kernel_size=(3, 3), input_shape=x_train.shape[1:], activation =\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Conv2D(128, kernel_size=(3, 3), input_shape=x_train.shape[1:], activation =\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(80, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,609,546\n",
      "Trainable params: 1,609,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 2.0416 - accuracy: 0.2514 - val_loss: 1.8092 - val_accuracy: 0.3521\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 1.6836 - accuracy: 0.3968 - val_loss: 1.4900 - val_accuracy: 0.4651\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 1.4959 - accuracy: 0.4650 - val_loss: 1.4058 - val_accuracy: 0.5038\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 1.3950 - accuracy: 0.5015 - val_loss: 1.2874 - val_accuracy: 0.5439\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 1.3141 - accuracy: 0.5286 - val_loss: 1.2142 - val_accuracy: 0.5696\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 1.2461 - accuracy: 0.5562 - val_loss: 1.2072 - val_accuracy: 0.5787\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 1.1782 - accuracy: 0.5823 - val_loss: 1.0970 - val_accuracy: 0.6104\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 1.1196 - accuracy: 0.6034 - val_loss: 1.0382 - val_accuracy: 0.6339\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 1.0598 - accuracy: 0.6259 - val_loss: 1.0191 - val_accuracy: 0.6461\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 1.0125 - accuracy: 0.6423 - val_loss: 0.9485 - val_accuracy: 0.6679\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.9615 - accuracy: 0.6632 - val_loss: 0.9654 - val_accuracy: 0.6566\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.9162 - accuracy: 0.6802 - val_loss: 0.9213 - val_accuracy: 0.6801\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.8743 - accuracy: 0.6939 - val_loss: 0.8505 - val_accuracy: 0.7015\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.8336 - accuracy: 0.7094 - val_loss: 0.8468 - val_accuracy: 0.7176\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.7963 - accuracy: 0.7234 - val_loss: 0.7652 - val_accuracy: 0.7304\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.7647 - accuracy: 0.7320 - val_loss: 0.7456 - val_accuracy: 0.7447\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.7319 - accuracy: 0.7455 - val_loss: 0.7323 - val_accuracy: 0.7493\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.7069 - accuracy: 0.7529 - val_loss: 0.7310 - val_accuracy: 0.7503\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.6834 - accuracy: 0.7619 - val_loss: 0.7043 - val_accuracy: 0.7610\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.6583 - accuracy: 0.7693 - val_loss: 0.7030 - val_accuracy: 0.7584\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.6373 - accuracy: 0.7766 - val_loss: 0.6632 - val_accuracy: 0.7737\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.6162 - accuracy: 0.7828 - val_loss: 0.6474 - val_accuracy: 0.7808\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.5952 - accuracy: 0.7907 - val_loss: 0.6705 - val_accuracy: 0.7719\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.5806 - accuracy: 0.7965 - val_loss: 0.6530 - val_accuracy: 0.7799\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.5623 - accuracy: 0.8024 - val_loss: 0.6209 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 0.5464 - accuracy: 0.8069 - val_loss: 0.6070 - val_accuracy: 0.7944\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 241s 154ms/step - loss: 0.5275 - accuracy: 0.8162 - val_loss: 0.6500 - val_accuracy: 0.7765\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.5141 - accuracy: 0.8200 - val_loss: 0.6126 - val_accuracy: 0.7921\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.5008 - accuracy: 0.8242 - val_loss: 0.6491 - val_accuracy: 0.7839\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.4869 - accuracy: 0.8280 - val_loss: 0.5974 - val_accuracy: 0.7940\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 241s 154ms/step - loss: 0.4722 - accuracy: 0.8355 - val_loss: 0.5752 - val_accuracy: 0.8048\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.4583 - accuracy: 0.8397 - val_loss: 0.5915 - val_accuracy: 0.8005\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.4446 - accuracy: 0.8448 - val_loss: 0.5874 - val_accuracy: 0.8064\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.4372 - accuracy: 0.8457 - val_loss: 0.5778 - val_accuracy: 0.8067\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.4231 - accuracy: 0.8493 - val_loss: 0.5815 - val_accuracy: 0.8083\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.4075 - accuracy: 0.8560 - val_loss: 0.5933 - val_accuracy: 0.8069\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.4015 - accuracy: 0.8590 - val_loss: 0.5791 - val_accuracy: 0.8087\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3919 - accuracy: 0.8622 - val_loss: 0.6333 - val_accuracy: 0.7969\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3792 - accuracy: 0.8669 - val_loss: 0.6079 - val_accuracy: 0.8092\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3694 - accuracy: 0.8694 - val_loss: 0.5770 - val_accuracy: 0.8085\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.3598 - accuracy: 0.8721 - val_loss: 0.5777 - val_accuracy: 0.8162\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3489 - accuracy: 0.8767 - val_loss: 0.6162 - val_accuracy: 0.8072\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3416 - accuracy: 0.8805 - val_loss: 0.6115 - val_accuracy: 0.8156\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3357 - accuracy: 0.8801 - val_loss: 0.5613 - val_accuracy: 0.8230\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3235 - accuracy: 0.8857 - val_loss: 0.5937 - val_accuracy: 0.8189\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.3198 - accuracy: 0.8884 - val_loss: 0.5798 - val_accuracy: 0.8219\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.3044 - accuracy: 0.8912 - val_loss: 0.6027 - val_accuracy: 0.8185\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2990 - accuracy: 0.8940 - val_loss: 0.6063 - val_accuracy: 0.8177\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2970 - accuracy: 0.8949 - val_loss: 0.5820 - val_accuracy: 0.8251\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2867 - accuracy: 0.8978 - val_loss: 0.6292 - val_accuracy: 0.8188\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2806 - accuracy: 0.9009 - val_loss: 0.6138 - val_accuracy: 0.8203\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2734 - accuracy: 0.9023 - val_loss: 0.6142 - val_accuracy: 0.8227\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2622 - accuracy: 0.9053 - val_loss: 0.6025 - val_accuracy: 0.8254\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2561 - accuracy: 0.9078 - val_loss: 0.6385 - val_accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2519 - accuracy: 0.9100 - val_loss: 0.5901 - val_accuracy: 0.8243\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2437 - accuracy: 0.9133 - val_loss: 0.6168 - val_accuracy: 0.8235\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2448 - accuracy: 0.9124 - val_loss: 0.6194 - val_accuracy: 0.8212\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2365 - accuracy: 0.9164 - val_loss: 0.6259 - val_accuracy: 0.8261\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2294 - accuracy: 0.9192 - val_loss: 0.6305 - val_accuracy: 0.8303\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2252 - accuracy: 0.9197 - val_loss: 0.6150 - val_accuracy: 0.8267\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2196 - accuracy: 0.9222 - val_loss: 0.6286 - val_accuracy: 0.8262\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2165 - accuracy: 0.9234 - val_loss: 0.6502 - val_accuracy: 0.8228\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2126 - accuracy: 0.9248 - val_loss: 0.6511 - val_accuracy: 0.8310\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2075 - accuracy: 0.9267 - val_loss: 0.6388 - val_accuracy: 0.8300\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2003 - accuracy: 0.9282 - val_loss: 0.6294 - val_accuracy: 0.8324\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1965 - accuracy: 0.9297 - val_loss: 0.6504 - val_accuracy: 0.8261\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1970 - accuracy: 0.9309 - val_loss: 0.6786 - val_accuracy: 0.8243\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1911 - accuracy: 0.9320 - val_loss: 0.7265 - val_accuracy: 0.8185\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1845 - accuracy: 0.9344 - val_loss: 0.6746 - val_accuracy: 0.8294\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1835 - accuracy: 0.9352 - val_loss: 0.6720 - val_accuracy: 0.8296\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1819 - accuracy: 0.9353 - val_loss: 0.6454 - val_accuracy: 0.8334\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1712 - accuracy: 0.9382 - val_loss: 0.6421 - val_accuracy: 0.8334\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1688 - accuracy: 0.9405 - val_loss: 0.6903 - val_accuracy: 0.8275\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1690 - accuracy: 0.9386 - val_loss: 0.6527 - val_accuracy: 0.8342\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1608 - accuracy: 0.9432 - val_loss: 0.7287 - val_accuracy: 0.8193\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1627 - accuracy: 0.9411 - val_loss: 0.6612 - val_accuracy: 0.8353\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1547 - accuracy: 0.9449 - val_loss: 0.7842 - val_accuracy: 0.8210\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1540 - accuracy: 0.9462 - val_loss: 0.7593 - val_accuracy: 0.8277\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1516 - accuracy: 0.9449 - val_loss: 0.6911 - val_accuracy: 0.8346\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.1545 - accuracy: 0.9457 - val_loss: 0.7279 - val_accuracy: 0.8289\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1444 - accuracy: 0.9486 - val_loss: 0.7825 - val_accuracy: 0.8258\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1453 - accuracy: 0.9489 - val_loss: 0.7357 - val_accuracy: 0.8288\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1425 - accuracy: 0.9491 - val_loss: 0.7408 - val_accuracy: 0.8238\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1395 - accuracy: 0.9500 - val_loss: 0.7017 - val_accuracy: 0.8302\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1338 - accuracy: 0.9524 - val_loss: 0.7291 - val_accuracy: 0.8346\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1336 - accuracy: 0.9524 - val_loss: 0.7405 - val_accuracy: 0.8329\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1304 - accuracy: 0.9537 - val_loss: 0.7214 - val_accuracy: 0.8361\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1319 - accuracy: 0.9538 - val_loss: 0.7103 - val_accuracy: 0.8329\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1276 - accuracy: 0.9548 - val_loss: 0.7935 - val_accuracy: 0.8272\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1285 - accuracy: 0.9549 - val_loss: 0.7560 - val_accuracy: 0.8364\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1237 - accuracy: 0.9558 - val_loss: 0.7418 - val_accuracy: 0.8369\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1253 - accuracy: 0.9559 - val_loss: 0.7423 - val_accuracy: 0.8286\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1222 - accuracy: 0.9565 - val_loss: 0.7167 - val_accuracy: 0.8339\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1187 - accuracy: 0.9576 - val_loss: 0.7514 - val_accuracy: 0.8339\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1194 - accuracy: 0.9575 - val_loss: 0.7883 - val_accuracy: 0.8336\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1172 - accuracy: 0.9585 - val_loss: 0.7680 - val_accuracy: 0.8360\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1175 - accuracy: 0.9581 - val_loss: 0.7162 - val_accuracy: 0.8387\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1102 - accuracy: 0.9614 - val_loss: 0.7333 - val_accuracy: 0.8339\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1128 - accuracy: 0.9606 - val_loss: 0.8021 - val_accuracy: 0.8252\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.1097 - accuracy: 0.9614 - val_loss: 0.7864 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa91317ef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate SGD optimizer\n",
    "opt = keras.optimizers.SGD()\n",
    "\n",
    "# Compile the model with loss function and optimizer, and evaluate with accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Setup some hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Fit the data into model\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           shuffle=True)\n",
    "\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape) # 10000 samples, each sample with probaility of 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.8483463e-10, 9.9994767e-01, 4.0732859e-16, 1.4080867e-13,\n",
       "       4.6837758e-19, 5.7670383e-18, 3.8534833e-22, 1.8081096e-16,\n",
       "       1.1512043e-16, 5.2376196e-05], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[0]) # argmax to find the predict class with highest probability. 9=truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT MODIFY CODE BELOW!\n",
    "**Please screen shot your results and post it on your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (10000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my model on test set:  0.833\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load(\"y_test.npy\")\n",
    "print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
